{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Feature Selection - On Decision Tree Classifier (Ensembling Method) \n",
    "\n",
    "we will use a random selection of features prior to model building to add additional variance to the individual trees. While an individual tree may perform worse, sometimes the increases in variance can help model performance of the ensemble model as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of DT on test set (trained using full feature set):\n",
      "0.9467592592592593\n",
      "Accuracy score of DT on test set (trained using random feature sample):\n",
      "0.8009259259259259\n",
      "Accuracy score of aggregated 10 samples:\n",
      "0.7476851851851852\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])\n",
    "df['accep'] = ~(df['accep']=='unacc') #1 is acceptable, 0 if not acceptable\n",
    "X = pd.get_dummies(df.iloc[:,0:6], drop_first=True)\n",
    "y = df['accep']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state=0, test_size=0.25)\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "print(\"Accuracy score of DT on test set (trained using full feature set):\")\n",
    "accuracy_dt = dt.score(x_test, y_test)\n",
    "print(accuracy_dt)\n",
    "\n",
    "# 1. Created rand_features, random samples from the set of features\n",
    "rand_features = np.random.choice(x_train.columns,10)\n",
    "\n",
    "# Made new decision tree trained on random sample of 10 features and calculate the new accuracy score\n",
    "dt2 = DecisionTreeClassifier()\n",
    "\n",
    "dt2.fit(x_train[rand_features], y_train)\n",
    "print(\"Accuracy score of DT on test set (trained using random feature sample):\")\n",
    "accuracy_dt2 = dt2.score(x_test[rand_features], y_test)\n",
    "print(accuracy_dt2)\n",
    "\n",
    "# 2. Building decision trees on 10 different random samples \n",
    "predictions = []\n",
    "for i in range(10):\n",
    "    rand_features = np.random.choice(x_train.columns,10)\n",
    "    dt2.fit(x_train[rand_features], y_train)\n",
    "    predictions.append(dt2.predict(x_test[rand_features]))\n",
    "\n",
    "## 3. Getting aggregate predictions and accuracy score\n",
    "prob_predictions = np.array(predictions).mean(0)\n",
    "agg_predictions = (prob_predictions>0.5)\n",
    "agg_accuracy = accuracy_score(agg_predictions, y_test)\n",
    "print('Accuracy score of aggregated 10 samples:')\n",
    "print(agg_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
